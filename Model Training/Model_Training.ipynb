{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ac67ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /home/taksh/Documents/code/research/venv/lib/python3.12/site-packages (2.4.1)\n",
      "Requirement already satisfied: matplotlib in /home/taksh/Documents/code/research/venv/lib/python3.12/site-packages (3.10.8)\n",
      "Collecting scipy\n",
      "  Using cached scipy-1.17.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
      "Collecting tensorflow[and-cuda]\n",
      "  Using cached tensorflow-2.20.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.5 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow[and-cuda])\n",
      "  Using cached absl_py-2.4.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow[and-cuda])\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow[and-cuda])\n",
      "  Using cached flatbuffers-25.12.19-py2.py3-none-any.whl.metadata (1.0 kB)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow[and-cuda])\n",
      "  Using cached gast-0.7.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting google_pasta>=0.1.1 (from tensorflow[and-cuda])\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow[and-cuda])\n",
      "  Using cached libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting opt_einsum>=2.3.2 (from tensorflow[and-cuda])\n",
      "  Using cached opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in /home/taksh/Documents/code/research/venv/lib/python3.12/site-packages (from tensorflow[and-cuda]) (25.0)\n",
      "Collecting protobuf>=5.28.0 (from tensorflow[and-cuda])\n",
      "  Using cached protobuf-6.33.5-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
      "Collecting requests<3,>=2.21.0 (from tensorflow[and-cuda])\n",
      "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting setuptools (from tensorflow[and-cuda])\n",
      "  Using cached setuptools-80.10.2-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/taksh/Documents/code/research/venv/lib/python3.12/site-packages (from tensorflow[and-cuda]) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow[and-cuda])\n",
      "  Using cached termcolor-3.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting typing_extensions>=3.6.6 (from tensorflow[and-cuda])\n",
      "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow[and-cuda])\n",
      "  Using cached wrapt-2.1.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (7.4 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow[and-cuda])\n",
      "  Using cached grpcio-1.76.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.7 kB)\n",
      "Collecting tensorboard~=2.20.0 (from tensorflow[and-cuda])\n",
      "  Using cached tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.10.0 (from tensorflow[and-cuda])\n",
      "  Using cached keras-3.13.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting h5py>=3.11.0 (from tensorflow[and-cuda])\n",
      "  Using cached h5py-3.15.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting ml_dtypes<1.0.0,>=0.5.1 (from tensorflow[and-cuda])\n",
      "  Using cached ml_dtypes-0.5.4-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.9 kB)\n",
      "Collecting nvidia-cublas-cu12<13.0,>=12.5.3.2 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_cublas_cu12-12.9.1.4-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12<13.0,>=12.5.82 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.9.79-py3-none-manylinux_2_25_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cuda-nvcc-cu12<13.0,>=12.5.82 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_cuda_nvcc_cu12-12.9.86-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12<13.0,>=12.5.82 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.9.86-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12<13.0,>=12.5.82 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.9.79-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cudnn-cu12<10.0,>=9.3.0.75 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_cudnn_cu12-9.18.1.3-py3-none-manylinux_2_27_x86_64.whl.metadata (1.9 kB)\n",
      "Collecting nvidia-cufft-cu12<12.0,>=11.2.3.61 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_cufft_cu12-11.4.1.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-curand-cu12<11.0,>=10.3.6.82 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_curand_cu12-10.3.10.19-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cusolver-cu12<12.0,>=11.6.3.83 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_cusolver_cu12-11.7.5.82-py3-none-manylinux_2_27_x86_64.whl.metadata (1.9 kB)\n",
      "Collecting nvidia-cusparse-cu12<13.0,>=12.5.1.3 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_cusparse_cu12-12.5.10.65-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nccl-cu12<3.0,>=2.25.1 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_nccl_cu12-2.29.2-py3-none-manylinux_2_18_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting nvidia-nvjitlink-cu12<13.0,>=12.5.82 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_nvjitlink_cu12-12.9.86-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/taksh/Documents/code/research/venv/lib/python3.12/site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/taksh/Documents/code/research/venv/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/taksh/Documents/code/research/venv/lib/python3.12/site-packages (from matplotlib) (4.61.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/taksh/Documents/code/research/venv/lib/python3.12/site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: pillow>=8 in /home/taksh/Documents/code/research/venv/lib/python3.12/site-packages (from matplotlib) (12.1.0)\n",
      "Requirement already satisfied: pyparsing>=3 in /home/taksh/Documents/code/research/venv/lib/python3.12/site-packages (from matplotlib) (3.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/taksh/Documents/code/research/venv/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow[and-cuda])\n",
      "  Using cached wheel-0.46.3-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting rich (from keras>=3.10.0->tensorflow[and-cuda])\n",
      "  Using cached rich-14.3.2-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.10.0->tensorflow[and-cuda])\n",
      "  Using cached namex-0.1.0-py3-none-any.whl.metadata (322 bytes)\n",
      "Collecting optree (from keras>=3.10.0->tensorflow[and-cuda])\n",
      "  Using cached optree-0.18.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (34 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests<3,>=2.21.0->tensorflow[and-cuda])\n",
      "  Using cached charset_normalizer-3.4.4-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (37 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3,>=2.21.0->tensorflow[and-cuda])\n",
      "  Using cached idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2.21.0->tensorflow[and-cuda])\n",
      "  Using cached urllib3-2.6.3-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests<3,>=2.21.0->tensorflow[and-cuda])\n",
      "  Using cached certifi-2026.1.4-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard~=2.20.0->tensorflow[and-cuda])\n",
      "  Using cached markdown-3.10.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.20.0->tensorflow[and-cuda])\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard~=2.20.0->tensorflow[and-cuda])\n",
      "  Using cached werkzeug-3.1.5-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting markupsafe>=2.1.1 (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow[and-cuda])\n",
      "  Using cached markupsafe-3.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.7 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.10.0->tensorflow[and-cuda])\n",
      "  Using cached markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/taksh/Documents/code/research/venv/lib/python3.12/site-packages (from rich->keras>=3.10.0->tensorflow[and-cuda]) (2.19.2)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow[and-cuda])\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Using cached scipy-1.17.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (35.0 MB)\n",
      "Using cached absl_py-2.4.0-py3-none-any.whl (135 kB)\n",
      "Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Using cached flatbuffers-25.12.19-py2.py3-none-any.whl (26 kB)\n",
      "Using cached gast-0.7.0-py3-none-any.whl (22 kB)\n",
      "Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Using cached grpcio-1.76.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (6.6 MB)\n",
      "Using cached h5py-3.15.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (5.1 MB)\n",
      "Using cached keras-3.13.2-py3-none-any.whl (1.5 MB)\n",
      "Using cached libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
      "Using cached ml_dtypes-0.5.4-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (5.0 MB)\n",
      "Using cached nvidia_cublas_cu12-12.9.1.4-py3-none-manylinux_2_27_x86_64.whl (581.2 MB)\n",
      "Using cached nvidia_cuda_cupti_cu12-12.9.79-py3-none-manylinux_2_25_x86_64.whl (10.8 MB)\n",
      "Using cached nvidia_cuda_nvcc_cu12-12.9.86-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (40.5 MB)\n",
      "Using cached nvidia_cuda_nvrtc_cu12-12.9.86-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (89.6 MB)\n",
      "Using cached nvidia_cuda_runtime_cu12-12.9.79-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.5 MB)\n",
      "Downloading nvidia_cudnn_cu12-9.18.1.3-py3-none-manylinux_2_27_x86_64.whl (648.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m648.6/648.6 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:10\u001b[0mm\n",
      "\u001b[?25hUsing cached nvidia_cufft_cu12-11.4.1.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.9 MB)\n",
      "Using cached nvidia_curand_cu12-10.3.10.19-py3-none-manylinux_2_27_x86_64.whl (68.3 MB)\n",
      "Using cached nvidia_cusolver_cu12-11.7.5.82-py3-none-manylinux_2_27_x86_64.whl (338.1 MB)\n",
      "Using cached nvidia_cusparse_cu12-12.5.10.65-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (366.5 MB)\n",
      "Using cached nvidia_nccl_cu12-2.29.2-py3-none-manylinux_2_18_x86_64.whl (289.8 MB)\n",
      "Using cached nvidia_nvjitlink_cu12-12.9.86-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.7 MB)\n",
      "Using cached opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading protobuf-6.33.5-cp39-abi3-manylinux2014_x86_64.whl (323 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m323.5/323.5 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hUsing cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Using cached tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
      "Downloading setuptools-80.10.2-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached termcolor-3.3.0-py3-none-any.whl (7.7 kB)\n",
      "Using cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Downloading wrapt-2.1.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (121 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.3/121.3 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached tensorflow-2.20.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (620.7 MB)\n",
      "Using cached certifi-2026.1.4-py3-none-any.whl (152 kB)\n",
      "Using cached charset_normalizer-3.4.4-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (153 kB)\n",
      "Using cached idna-3.11-py3-none-any.whl (71 kB)\n",
      "Downloading markdown-3.10.1-py3-none-any.whl (107 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.7/107.7 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "Using cached urllib3-2.6.3-py3-none-any.whl (131 kB)\n",
      "Using cached werkzeug-3.1.5-py3-none-any.whl (225 kB)\n",
      "Downloading wheel-0.46.3-py3-none-any.whl (30 kB)\n",
      "Using cached namex-0.1.0-py3-none-any.whl (5.9 kB)\n",
      "Using cached optree-0.18.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (408 kB)\n",
      "Downloading rich-14.3.2-py3-none-any.whl (309 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.0/310.0 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached markupsafe-3.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (22 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, wheel, urllib3, typing_extensions, termcolor, tensorboard-data-server, setuptools, scipy, protobuf, opt_einsum, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-nvcc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ml_dtypes, mdurl, markupsafe, markdown, idna, h5py, google_pasta, gast, charset_normalizer, certifi, absl-py, werkzeug, requests, optree, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, markdown-it-py, grpcio, astunparse, tensorboard, rich, nvidia-cusolver-cu12, keras, tensorflow\n",
      "Successfully installed absl-py-2.4.0 astunparse-1.6.3 certifi-2026.1.4 charset_normalizer-3.4.4 flatbuffers-25.12.19 gast-0.7.0 google_pasta-0.2.0 grpcio-1.76.0 h5py-3.15.1 idna-3.11 keras-3.13.2 libclang-18.1.1 markdown-3.10.1 markdown-it-py-4.0.0 markupsafe-3.0.3 mdurl-0.1.2 ml_dtypes-0.5.4 namex-0.1.0 nvidia-cublas-cu12-12.9.1.4 nvidia-cuda-cupti-cu12-12.9.79 nvidia-cuda-nvcc-cu12-12.9.86 nvidia-cuda-nvrtc-cu12-12.9.86 nvidia-cuda-runtime-cu12-12.9.79 nvidia-cudnn-cu12-9.18.1.3 nvidia-cufft-cu12-11.4.1.4 nvidia-curand-cu12-10.3.10.19 nvidia-cusolver-cu12-11.7.5.82 nvidia-cusparse-cu12-12.5.10.65 nvidia-nccl-cu12-2.29.2 nvidia-nvjitlink-cu12-12.9.86 opt_einsum-3.4.0 optree-0.18.0 protobuf-6.33.5 requests-2.32.5 rich-14.3.2 scipy-1.17.0 setuptools-80.10.2 tensorboard-2.20.0 tensorboard-data-server-0.7.2 tensorflow-2.20.0 termcolor-3.3.0 typing_extensions-4.15.0 urllib3-2.6.3 werkzeug-3.1.5 wheel-0.46.3 wrapt-2.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install TensorFlow with GPU support and plotting libraries\n",
    "%pip install \"tensorflow[and-cuda]\" numpy matplotlib scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf86a873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running from: /home/taksh/Documents/code/research/venv/bin/python\n",
      "Requirement already satisfied: numpy in /home/taksh/Documents/code/research/venv/lib/python3.12/site-packages (2.4.1)\n",
      "Requirement already satisfied: matplotlib in /home/taksh/Documents/code/research/venv/lib/python3.12/site-packages (3.10.8)\n",
      "Requirement already satisfied: scipy in /home/taksh/Documents/code/research/venv/lib/python3.12/site-packages (1.17.0)\n",
      "Requirement already satisfied: tensorflow[and-cuda] in /home/taksh/Documents/code/research/venv/lib/python3.12/site-packages (2.20.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/taksh/Documents/code/research/venv/lib/python3.12/site-packages (from tensorflow[and-cuda]) (2.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/taksh/Documents/code/research/venv/lib/python3.12/site-packages (from tensorflow[and-cuda]) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /home/taksh/Documents/code/research/venv/lib/python3.12/site-packages (from tensorflow[and-cuda]) (25.12.19)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /home/taksh/Documents/code/research/venv/lib/python3.12/site-packages (from tensorflow[and-cuda]) (0.7.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in /home/taksh/Documents/code/research/venv/lib/python3.12/site-packages (from tensorflow[and-cuda]) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/taksh/Documents/code/research/venv/lib/python3.12/site-packages (from tensorflow[and-cuda]) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in /home/taksh/Documents/code/research/venv/lib/python3.12/site-packages (from tensorflow[and-cuda]) (3.4.0)\n",
      "Requirement already satisfied: packaging in /home/taksh/Documents/code/research/venv/lib/python3.12/site-packages (from tensorflow[and-cuda]) (25.0)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in /home/taksh/Documents/code/research/venv/lib/python3.12/site-packages (from tensorflow[and-cuda]) (6.33.5)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/taksh/Documents/code/research/venv/lib/python3.12/site-packages (from tensorflow[and-cuda]) (2.32.5)\n",
      "Requirement already satisfied: setuptools in /home/taksh/Documents/code/research/venv/lib/python3.12/site-packages (from tensorflow[and-cuda]) (80.10.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/taksh/Documents/code/research/venv/lib/python3.12/site-packages (from tensorflow[and-cuda]) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/taksh/Documents/code/research/venv/lib/python3.12/site-packages (from tensorflow[and-cuda]) (3.3.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in /home/taksh/Documents/code/research/venv/lib/python3.12/site-packages (from tensorflow[and-cuda]) (4.15.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/taksh/Documents/code/research/venv/lib/python3.12/site-packages (from tensorflow[and-cuda]) (2.1.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/taksh/Documents/code/research/venv/lib/python3.12/site-packages (from tensorflow[and-cuda]) (1.76.0)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in /home/taksh/Documents/code/research/venv/lib/python3.12/site-packages (from tensorflow[and-cuda]) (2.20.0)\n",
      "Requirement already satisfied: keras>=3.10.0 in /home/taksh/Documents/code/research/venv/lib/python3.12/site-packages (from tensorflow[and-cuda]) (3.13.2)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /home/taksh/Documents/code/research/venv/lib/python3.12/site-packages (from tensorflow[and-cuda]) (3.15.1)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in /home/taksh/Documents/code/research/venv/lib/python3.12/site-packages (from tensorflow[and-cuda]) (0.5.4)\n",
      "Requirement already satisfied: nvidia-cublas-cu12<13.0,>=12.5.3.2 in /home/taksh/Documents/code/research/venv/lib/python3.12/site-packages (from tensorflow[and-cuda]) (12.9.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12<13.0,>=12.5.82 in /home/taksh/Documents/code/research/venv/lib/python3.12/site-packages (from tensorflow[and-cuda]) (12.9.79)\n",
      "Requirement already satisfied: nvidia-cuda-nvcc-cu12<13.0,>=12.5.82 in /home/taksh/Documents/code/research/venv/lib/python3.12/site-packages (from tensorflow[and-cuda]) (12.9.86)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12<13.0,>=12.5.82 in /home/taksh/Documents/code/research/venv/lib/python3.12/site-packages (from tensorflow[and-cuda]) (12.9.86)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12<13.0,>=12.5.82 in /home/taksh/Documents/code/research/venv/lib/python3.12/site-packages (from tensorflow[and-cuda]) (12.9.79)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12<10.0,>=9.3.0.75 in /home/taksh/Documents/code/research/venv/lib/python3.12/site-packages (from tensorflow[and-cuda]) (9.18.1.3)\n",
      "Requirement already satisfied: nvidia-cufft-cu12<12.0,>=11.2.3.61 in /home/taksh/Documents/code/research/venv/lib/python3.12/site-packages (from tensorflow[and-cuda]) (11.4.1.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12<11.0,>=10.3.6.82 in /home/taksh/Documents/code/research/venv/lib/python3.12/site-packages (from tensorflow[and-cuda]) (10.3.10.19)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12<12.0,>=11.6.3.83 in /home/taksh/Documents/code/research/venv/lib/python3.12/site-packages (from tensorflow[and-cuda]) (11.7.5.82)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12<13.0,>=12.5.1.3 in /home/taksh/Documents/code/research/venv/lib/python3.12/site-packages (from tensorflow[and-cuda]) (12.5.10.65)\n",
      "Requirement already satisfied: nvidia-nccl-cu12<3.0,>=2.25.1 in /home/taksh/Documents/code/research/venv/lib/python3.12/site-packages (from tensorflow[and-cuda]) (2.29.2)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12<13.0,>=12.5.82 in /home/taksh/Documents/code/research/venv/lib/python3.12/site-packages (from tensorflow[and-cuda]) (12.9.86)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/taksh/Documents/code/research/venv/lib/python3.12/site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/taksh/Documents/code/research/venv/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/taksh/Documents/code/research/venv/lib/python3.12/site-packages (from matplotlib) (4.61.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/taksh/Documents/code/research/venv/lib/python3.12/site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: pillow>=8 in /home/taksh/Documents/code/research/venv/lib/python3.12/site-packages (from matplotlib) (12.1.0)\n",
      "Requirement already satisfied: pyparsing>=3 in /home/taksh/Documents/code/research/venv/lib/python3.12/site-packages (from matplotlib) (3.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/taksh/Documents/code/research/venv/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/taksh/Documents/code/research/venv/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow[and-cuda]) (0.46.3)\n",
      "Requirement already satisfied: rich in /home/taksh/Documents/code/research/venv/lib/python3.12/site-packages (from keras>=3.10.0->tensorflow[and-cuda]) (14.3.2)\n",
      "Requirement already satisfied: namex in /home/taksh/Documents/code/research/venv/lib/python3.12/site-packages (from keras>=3.10.0->tensorflow[and-cuda]) (0.1.0)\n",
      "Requirement already satisfied: optree in /home/taksh/Documents/code/research/venv/lib/python3.12/site-packages (from keras>=3.10.0->tensorflow[and-cuda]) (0.18.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/taksh/Documents/code/research/venv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow[and-cuda]) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/taksh/Documents/code/research/venv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow[and-cuda]) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/taksh/Documents/code/research/venv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow[and-cuda]) (2.6.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/taksh/Documents/code/research/venv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow[and-cuda]) (2026.1.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/taksh/Documents/code/research/venv/lib/python3.12/site-packages (from tensorboard~=2.20.0->tensorflow[and-cuda]) (3.10.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/taksh/Documents/code/research/venv/lib/python3.12/site-packages (from tensorboard~=2.20.0->tensorflow[and-cuda]) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/taksh/Documents/code/research/venv/lib/python3.12/site-packages (from tensorboard~=2.20.0->tensorflow[and-cuda]) (3.1.5)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in /home/taksh/Documents/code/research/venv/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow[and-cuda]) (3.0.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/taksh/Documents/code/research/venv/lib/python3.12/site-packages (from rich->keras>=3.10.0->tensorflow[and-cuda]) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/taksh/Documents/code/research/venv/lib/python3.12/site-packages (from rich->keras>=3.10.0->tensorflow[and-cuda]) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/taksh/Documents/code/research/venv/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow[and-cuda]) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "# 1. Print where the notebook is actually running from\n",
    "print(f\"Running from: {sys.executable}\")\n",
    "\n",
    "# 2. Force install into THIS specific python\n",
    "!{sys.executable} -m pip install \"tensorflow[and-cuda]\" numpy matplotlib scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc229af",
   "metadata": {},
   "source": [
    "## 1. Imports & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef795027",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-02 11:46:09.654722: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2026-02-02 11:46:09.705642: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2026-02-02 11:46:10.663148: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.20.0\n",
      "Keras version: 3.13.2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tarfile\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from typing import Tuple, Dict, Callable\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.applications import VGG19, ResNet101, DenseNet121\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input as vgg_preprocess\n",
    "from tensorflow.keras.applications.resnet import preprocess_input as resnet_preprocess\n",
    "from tensorflow.keras.applications.densenet import preprocess_input as densenet_preprocess\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"Keras version: {keras.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48bbd0f",
   "metadata": {},
   "source": [
    "## 2. GPU Configuration & Mixed Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "147e8a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 GPU(s): ['/physical_device:GPU:0']\n",
      "Memory growth enabled for all GPUs\n",
      "Mixed precision policy: mixed_float16\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(f\"Found {len(gpus)} GPU(s): {[gpu.name for gpu in gpus]}\")\n",
    "        print(\"Memory growth enabled for all GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU configuration error: {e}\")\n",
    "else:\n",
    "    print(\"WARNING: No GPU found. Training will be slow on CPU.\")\n",
    "\n",
    "tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "print(f\"Mixed precision policy: {tf.keras.mixed_precision.global_policy().name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a6b271",
   "metadata": {},
   "source": [
    "## 3. Global Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08563025",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    'zip_file': 'caltech-101.zip',  # Changed from tar_file\n",
    "    'extract_dir': 'caltech101_data',\n",
    "    'img_size': (224, 224),\n",
    "    'batch_size': 32,\n",
    "    'epochs': 50,\n",
    "    'train_split': 0.8,\n",
    "    'val_split': 0.1,\n",
    "    'test_split': 0.1,\n",
    "    'seed': 42,\n",
    "    'learning_rate': 1e-4,\n",
    "    'patience_early_stop': 10,\n",
    "    'patience_lr_reduce': 5,\n",
    "}\n",
    "\n",
    "MODELS_TO_TRAIN = ['VGG19', 'ResNet101', 'DenseNet121']\n",
    "CHECKPOINT_DIR = Path('checkpoints')\n",
    "CHECKPOINT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "np.random.seed(CONFIG['seed'])\n",
    "tf.random.set_seed(CONFIG['seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13cc3e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Tar file not found: Caltech_WebFaces.tar",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     18\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExtraction complete: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mextract_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     19\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m extract_path\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m data_root = \u001b[43mextract_tar_if_needed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCONFIG\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtar_file\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCONFIG\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mextract_dir\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfind_image_root\u001b[39m(base_path: Path) -> Path:\n\u001b[32m     24\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Find the actual root containing class folders with images.\"\"\"\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36mextract_tar_if_needed\u001b[39m\u001b[34m(tar_path, extract_dir)\u001b[39m\n\u001b[32m      7\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m extract_path\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Path(tar_path).exists():\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTar file not found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtar_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExtracting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtar_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     13\u001b[39m extract_path.mkdir(parents=\u001b[38;5;28;01mTrue\u001b[39;00m, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: Tar file not found: Caltech_WebFaces.tar"
     ]
    }
   ],
   "source": [
    "def extract_zip_if_needed(zip_path: str, extract_dir: str) -> Path:\n",
    "    \"\"\"Extract zip file if not already extracted.\"\"\"\n",
    "    extract_path = Path(extract_dir)\n",
    "    \n",
    "    if extract_path.exists() and any(extract_path.iterdir()):\n",
    "        print(f\"Data already extracted at: {extract_path}\")\n",
    "        return extract_path\n",
    "    \n",
    "    if not Path(zip_path).exists():\n",
    "        raise FileNotFoundError(f\"Zip file not found: {zip_path}\")\n",
    "    \n",
    "    print(f\"Extracting {zip_path}...\")\n",
    "    extract_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(path=extract_path)\n",
    "    \n",
    "    print(f\"Extraction complete: {extract_path}\")\n",
    "    return extract_path\n",
    "\n",
    "data_root = extract_zip_if_needed(CONFIG['zip_file'], CONFIG['extract_dir'])\n",
    "\n",
    "def find_image_root(base_path: Path) -> Path:\n",
    "    \"\"\"Find the actual root containing class folders with images.\"\"\"\n",
    "    # First, look for common Caltech-101 directory structures\n",
    "    possible_roots = [\n",
    "        base_path / '101_ObjectCategories',\n",
    "        base_path / 'caltech-101' / '101_ObjectCategories',\n",
    "        base_path / 'caltech101' / '101_ObjectCategories',\n",
    "    ]\n",
    "    \n",
    "    for root in possible_roots:\n",
    "        if root.exists() and root.is_dir():\n",
    "            return root\n",
    "    \n",
    "    # Fallback: search for image files\n",
    "    for item in base_path.rglob('*'):\n",
    "        if item.is_file() and item.suffix.lower() in ['.jpg', '.jpeg', '.png', '.gif', '.bmp']:\n",
    "            return item.parent.parent\n",
    "    \n",
    "    # Another fallback: find directory with subdirectories\n",
    "    for subdir in base_path.iterdir():\n",
    "        if subdir.is_dir():\n",
    "            subdirs = list(subdir.iterdir())\n",
    "            if subdirs and all(s.is_dir() for s in subdirs[:5]):\n",
    "                return subdir\n",
    "    return base_path\n",
    "\n",
    "IMAGE_ROOT = find_image_root(data_root)\n",
    "print(f\"Image root directory: {IMAGE_ROOT}\")\n",
    "\n",
    "# List contents to verify\n",
    "print(f\"\\nContents of extract directory:\")\n",
    "for item in sorted(data_root.iterdir())[:10]:\n",
    "    print(f\"  {item.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21cf2fb7",
   "metadata": {},
   "source": [
    "## 5. Dataset Discovery & Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b51a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_names_and_counts(image_root: Path) -> Tuple[list, dict]:\n",
    "    \"\"\"Get class names and image counts per class.\"\"\"\n",
    "    class_names = sorted([d.name for d in image_root.iterdir() if d.is_dir()])\n",
    "    class_counts = {}\n",
    "    \n",
    "    for class_name in class_names:\n",
    "        class_dir = image_root / class_name\n",
    "        count = len([f for f in class_dir.iterdir() \n",
    "                     if f.is_file() and f.suffix.lower() in ['.jpg', '.jpeg', '.png', '.gif', '.bmp']])\n",
    "        class_counts[class_name] = count\n",
    "    \n",
    "    return class_names, class_counts\n",
    "\n",
    "CLASS_NAMES, CLASS_COUNTS = get_class_names_and_counts(IMAGE_ROOT)\n",
    "NUM_CLASSES = len(CLASS_NAMES)\n",
    "TOTAL_IMAGES = sum(CLASS_COUNTS.values())\n",
    "\n",
    "print(f\"Number of classes: {NUM_CLASSES}\")\n",
    "print(f\"Total images: {TOTAL_IMAGES}\")\n",
    "print(f\"\\nSample classes: {CLASS_NAMES[:10]}...\")\n",
    "print(f\"\\nClass distribution (first 10):\")\n",
    "for cls in list(CLASS_COUNTS.keys())[:10]:\n",
    "    print(f\"  {cls}: {CLASS_COUNTS[cls]} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3973d1b5",
   "metadata": {},
   "source": [
    "## 6. Create tf.data.Dataset with Train/Val/Test Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d588826",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_all_image_paths_and_labels(image_root: Path, class_names: list) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Collect all image paths and their corresponding labels.\"\"\"\n",
    "    all_paths = []\n",
    "    all_labels = []\n",
    "    class_to_idx = {name: idx for idx, name in enumerate(class_names)}\n",
    "    \n",
    "    for class_name in class_names:\n",
    "        class_dir = image_root / class_name\n",
    "        for img_path in class_dir.iterdir():\n",
    "            if img_path.is_file() and img_path.suffix.lower() in ['.jpg', '.jpeg', '.png', '.gif', '.bmp']:\n",
    "                all_paths.append(str(img_path))\n",
    "                all_labels.append(class_to_idx[class_name])\n",
    "    \n",
    "    return np.array(all_paths), np.array(all_labels)\n",
    "\n",
    "all_paths, all_labels = collect_all_image_paths_and_labels(IMAGE_ROOT, CLASS_NAMES)\n",
    "\n",
    "indices = np.arange(len(all_paths))\n",
    "np.random.shuffle(indices)\n",
    "all_paths = all_paths[indices]\n",
    "all_labels = all_labels[indices]\n",
    "\n",
    "train_size = int(CONFIG['train_split'] * len(all_paths))\n",
    "val_size = int(CONFIG['val_split'] * len(all_paths))\n",
    "\n",
    "train_paths, train_labels = all_paths[:train_size], all_labels[:train_size]\n",
    "val_paths, val_labels = all_paths[train_size:train_size+val_size], all_labels[train_size:train_size+val_size]\n",
    "test_paths, test_labels = all_paths[train_size+val_size:], all_labels[train_size+val_size:]\n",
    "\n",
    "print(f\"Train samples: {len(train_paths)}\")\n",
    "print(f\"Validation samples: {len(val_paths)}\")\n",
    "print(f\"Test samples: {len(test_paths)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b7745c",
   "metadata": {},
   "source": [
    "## 7. Dataset Pipeline Factory (with Model-Specific Preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28bbf96",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREPROCESS_FUNCTIONS = {\n",
    "    'VGG19': vgg_preprocess,\n",
    "    'ResNet101': resnet_preprocess,\n",
    "    'DenseNet121': densenet_preprocess,\n",
    "}\n",
    "\n",
    "def create_dataset_pipeline(\n",
    "    paths: np.ndarray,\n",
    "    labels: np.ndarray,\n",
    "    preprocess_fn: Callable,\n",
    "    img_size: Tuple[int, int],\n",
    "    batch_size: int,\n",
    "    shuffle: bool = False,\n",
    "    augment: bool = False\n",
    ") -> tf.data.Dataset:\n",
    "    \"\"\"Create an optimized tf.data pipeline with model-specific preprocessing.\"\"\"\n",
    "    \n",
    "    def load_and_preprocess(path, label):\n",
    "        img = tf.io.read_file(path)\n",
    "        img = tf.image.decode_image(img, channels=3, expand_animations=False)\n",
    "        img = tf.image.resize(img, img_size)\n",
    "        img = tf.cast(img, tf.float32)\n",
    "        img = preprocess_fn(img)\n",
    "        return img, label\n",
    "    \n",
    "    def augment_image(img, label):\n",
    "        img = tf.image.random_flip_left_right(img)\n",
    "        img = tf.image.random_brightness(img, 0.1)\n",
    "        img = tf.image.random_contrast(img, 0.9, 1.1)\n",
    "        return img, label\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices((paths, labels))\n",
    "    \n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(buffer_size=len(paths), seed=CONFIG['seed'])\n",
    "    \n",
    "    dataset = dataset.map(load_and_preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    \n",
    "    if augment:\n",
    "        dataset = dataset.map(augment_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    \n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "def get_datasets_for_model(model_name: str) -> Tuple[tf.data.Dataset, tf.data.Dataset, tf.data.Dataset]:\n",
    "    \"\"\"Create train, val, test datasets with model-specific preprocessing.\"\"\"\n",
    "    preprocess_fn = PREPROCESS_FUNCTIONS[model_name]\n",
    "    \n",
    "    train_ds = create_dataset_pipeline(\n",
    "        train_paths, train_labels, preprocess_fn,\n",
    "        CONFIG['img_size'], CONFIG['batch_size'],\n",
    "        shuffle=True, augment=True\n",
    "    )\n",
    "    val_ds = create_dataset_pipeline(\n",
    "        val_paths, val_labels, preprocess_fn,\n",
    "        CONFIG['img_size'], CONFIG['batch_size'],\n",
    "        shuffle=False, augment=False\n",
    "    )\n",
    "    test_ds = create_dataset_pipeline(\n",
    "        test_paths, test_labels, preprocess_fn,\n",
    "        CONFIG['img_size'], CONFIG['batch_size'],\n",
    "        shuffle=False, augment=False\n",
    "    )\n",
    "    \n",
    "    return train_ds, val_ds, test_ds\n",
    "\n",
    "print(\"Dataset pipeline factory created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707735a2",
   "metadata": {},
   "source": [
    "## 8. Model Factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d06b457",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_MODELS = {\n",
    "    'VGG19': VGG19,\n",
    "    'ResNet101': ResNet101,\n",
    "    'DenseNet121': DenseNet121,\n",
    "}\n",
    "\n",
    "def create_model(model_name: str, num_classes: int, img_size: Tuple[int, int]) -> Model:\n",
    "    \"\"\"Create a transfer learning model with trainable classification head.\"\"\"\n",
    "    \n",
    "    base_model_class = BASE_MODELS[model_name]\n",
    "    \n",
    "    base_model = base_model_class(\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        input_shape=(*img_size, 3),\n",
    "        pooling=None\n",
    "    )\n",
    "    \n",
    "    base_model.trainable = False\n",
    "    \n",
    "    inputs = keras.Input(shape=(*img_size, 3))\n",
    "    x = base_model(inputs, training=False)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dense(512, activation='relu')(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    x = layers.Dense(256, activation='relu')(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax', dtype='float32')(x)\n",
    "    \n",
    "    model = Model(inputs, outputs, name=f\"{model_name}_transfer\")\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=CONFIG['learning_rate']),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "print(\"Model factory created.\")\n",
    "print(f\"Models available: {list(BASE_MODELS.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3164611",
   "metadata": {},
   "source": [
    "## 9. Callbacks Factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a23178f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_callbacks(model_name: str) -> list:\n",
    "    \"\"\"Create callbacks for training.\"\"\"\n",
    "    \n",
    "    checkpoint_path = CHECKPOINT_DIR / f\"{model_name}_best.keras\"\n",
    "    \n",
    "    callbacks = [\n",
    "        EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=CONFIG['patience_early_stop'],\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        ModelCheckpoint(\n",
    "            filepath=str(checkpoint_path),\n",
    "            monitor='val_accuracy',\n",
    "            save_best_only=True,\n",
    "            save_weights_only=False,\n",
    "            verbose=1\n",
    "        ),\n",
    "        ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=CONFIG['patience_lr_reduce'],\n",
    "            min_lr=1e-7,\n",
    "            verbose=1\n",
    "        ),\n",
    "    ]\n",
    "    \n",
    "    return callbacks\n",
    "\n",
    "print(\"Callbacks factory created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa03106",
   "metadata": {},
   "source": [
    "## 10. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a059c5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_histories: Dict[str, keras.callbacks.History] = {}\n",
    "trained_models: Dict[str, Model] = {}\n",
    "\n",
    "for model_name in MODELS_TO_TRAIN:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"Training {model_name}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "    train_ds, val_ds, test_ds = get_datasets_for_model(model_name)\n",
    "    \n",
    "    model = create_model(model_name, NUM_CLASSES, CONFIG['img_size'])\n",
    "    \n",
    "    print(f\"\\n{model_name} Summary:\")\n",
    "    print(f\"  Total params: {model.count_params():,}\")\n",
    "    trainable_params = sum([tf.reduce_prod(v.shape).numpy() for v in model.trainable_variables])\n",
    "    print(f\"  Trainable params: {trainable_params:,}\")\n",
    "    \n",
    "    callbacks = get_callbacks(model_name)\n",
    "    \n",
    "    history = model.fit(\n",
    "        train_ds,\n",
    "        validation_data=val_ds,\n",
    "        epochs=CONFIG['epochs'],\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    training_histories[model_name] = history\n",
    "    trained_models[model_name] = model\n",
    "    \n",
    "    print(f\"\\n{model_name} training complete!\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ALL MODELS TRAINED SUCCESSFULLY\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6b405e",
   "metadata": {},
   "source": [
    "## 11. Evaluation on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6997f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TEST SET EVALUATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "test_results = {}\n",
    "\n",
    "for model_name in MODELS_TO_TRAIN:\n",
    "    print(f\"\\nEvaluating {model_name}...\")\n",
    "    \n",
    "    _, _, test_ds = get_datasets_for_model(model_name)\n",
    "    \n",
    "    model = trained_models[model_name]\n",
    "    \n",
    "    loss, accuracy = model.evaluate(test_ds, verbose=0)\n",
    "    \n",
    "    test_results[model_name] = {\n",
    "        'loss': loss,\n",
    "        'accuracy': accuracy\n",
    "    }\n",
    "    \n",
    "    print(f\"  Test Loss: {loss:.4f}\")\n",
    "    print(f\"  Test Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL RESULTS SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\n{'Model':<15} {'Test Loss':<12} {'Test Accuracy':<15}\")\n",
    "print(\"-\" * 42)\n",
    "for model_name, results in test_results.items():\n",
    "    print(f\"{model_name:<15} {results['loss']:<12.4f} {results['accuracy']*100:.2f}%\")\n",
    "\n",
    "best_model = max(test_results.keys(), key=lambda k: test_results[k]['accuracy'])\n",
    "print(f\"\\nBest performing model: {best_model} with {test_results[best_model]['accuracy']*100:.2f}% accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc6e90a",
   "metadata": {},
   "source": [
    "## 12. Training Curves Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94ba0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(histories: Dict[str, keras.callbacks.History], metric: str = 'accuracy'):\n",
    "    \"\"\"Plot training curves for all models.\"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    colors = ['#1f77b4', '#ff7f0e', '#2ca02c']\n",
    "    \n",
    "    for idx, (model_name, history) in enumerate(histories.items()):\n",
    "        epochs = range(1, len(history.history[metric]) + 1)\n",
    "        \n",
    "        axes[0].plot(epochs, history.history[metric], \n",
    "                     color=colors[idx], linestyle='-', linewidth=2,\n",
    "                     label=f'{model_name} (Train)')\n",
    "        axes[0].plot(epochs, history.history[f'val_{metric}'], \n",
    "                     color=colors[idx], linestyle='--', linewidth=2,\n",
    "                     label=f'{model_name} (Val)')\n",
    "    \n",
    "    axes[0].set_title('Model Accuracy', fontsize=14, fontweight='bold')\n",
    "    axes[0].set_xlabel('Epoch', fontsize=12)\n",
    "    axes[0].set_ylabel('Accuracy', fontsize=12)\n",
    "    axes[0].legend(loc='lower right', fontsize=10)\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    axes[0].set_ylim([0, 1])\n",
    "    \n",
    "    for idx, (model_name, history) in enumerate(histories.items()):\n",
    "        epochs = range(1, len(history.history['loss']) + 1)\n",
    "        \n",
    "        axes[1].plot(epochs, history.history['loss'], \n",
    "                     color=colors[idx], linestyle='-', linewidth=2,\n",
    "                     label=f'{model_name} (Train)')\n",
    "        axes[1].plot(epochs, history.history['val_loss'], \n",
    "                     color=colors[idx], linestyle='--', linewidth=2,\n",
    "                     label=f'{model_name} (Val)')\n",
    "    \n",
    "    axes[1].set_title('Model Loss', fontsize=14, fontweight='bold')\n",
    "    axes[1].set_xlabel('Epoch', fontsize=12)\n",
    "    axes[1].set_ylabel('Loss', fontsize=12)\n",
    "    axes[1].legend(loc='upper right', fontsize=10)\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_curves.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(\"Training curves saved to: training_curves.png\")\n",
    "\n",
    "plot_training_history(training_histories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6472b2a3",
   "metadata": {},
   "source": [
    "## 13. Individual Model Training Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cff4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_individual_model_curves(histories: Dict[str, keras.callbacks.History]):\n",
    "    \"\"\"Plot individual training curves for each model.\"\"\"\n",
    "    n_models = len(histories)\n",
    "    fig, axes = plt.subplots(n_models, 2, figsize=(14, 5 * n_models))\n",
    "    \n",
    "    if n_models == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    for idx, (model_name, history) in enumerate(histories.items()):\n",
    "        epochs = range(1, len(history.history['accuracy']) + 1)\n",
    "        \n",
    "        axes[idx, 0].plot(epochs, history.history['accuracy'], 'b-', linewidth=2, label='Train')\n",
    "        axes[idx, 0].plot(epochs, history.history['val_accuracy'], 'r--', linewidth=2, label='Validation')\n",
    "        axes[idx, 0].set_title(f'{model_name} - Accuracy', fontsize=12, fontweight='bold')\n",
    "        axes[idx, 0].set_xlabel('Epoch')\n",
    "        axes[idx, 0].set_ylabel('Accuracy')\n",
    "        axes[idx, 0].legend()\n",
    "        axes[idx, 0].grid(True, alpha=0.3)\n",
    "        axes[idx, 0].set_ylim([0, 1])\n",
    "        \n",
    "        axes[idx, 1].plot(epochs, history.history['loss'], 'b-', linewidth=2, label='Train')\n",
    "        axes[idx, 1].plot(epochs, history.history['val_loss'], 'r--', linewidth=2, label='Validation')\n",
    "        axes[idx, 1].set_title(f'{model_name} - Loss', fontsize=12, fontweight='bold')\n",
    "        axes[idx, 1].set_xlabel('Epoch')\n",
    "        axes[idx, 1].set_ylabel('Loss')\n",
    "        axes[idx, 1].legend()\n",
    "        axes[idx, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('individual_training_curves.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(\"Individual curves saved to: individual_training_curves.png\")\n",
    "\n",
    "plot_individual_model_curves(training_histories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8aeed05",
   "metadata": {},
   "source": [
    "## 14. Model Comparison Bar Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902f828b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_comparison(test_results: dict):\n",
    "    \"\"\"Bar chart comparing test accuracy across models.\"\"\"\n",
    "    models = list(test_results.keys())\n",
    "    accuracies = [test_results[m]['accuracy'] * 100 for m in models]\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    colors = ['#3498db', '#e74c3c', '#2ecc71']\n",
    "    bars = ax.bar(models, accuracies, color=colors, edgecolor='black', linewidth=1.2)\n",
    "    \n",
    "    for bar, acc in zip(bars, accuracies):\n",
    "        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,\n",
    "                f'{acc:.2f}%', ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    ax.set_ylabel('Test Accuracy (%)', fontsize=12)\n",
    "    ax.set_xlabel('Model', fontsize=12)\n",
    "    ax.set_title('Model Comparison - Test Accuracy', fontsize=14, fontweight='bold')\n",
    "    ax.set_ylim([0, 100])\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('model_comparison.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(\"Model comparison saved to: model_comparison.png\")\n",
    "\n",
    "plot_model_comparison(test_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574f3365",
   "metadata": {},
   "source": [
    "## 15. Save Final Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8c65aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "FINAL_MODELS_DIR = Path('final_models')\n",
    "FINAL_MODELS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "for model_name, model in trained_models.items():\n",
    "    save_path = FINAL_MODELS_DIR / f\"{model_name}_final.keras\"\n",
    "    model.save(save_path)\n",
    "    print(f\"Saved {model_name} to: {save_path}\")\n",
    "\n",
    "class_names_path = FINAL_MODELS_DIR / 'class_names.txt'\n",
    "with open(class_names_path, 'w') as f:\n",
    "    for name in CLASS_NAMES:\n",
    "        f.write(f\"{name}\\n\")\n",
    "print(f\"Saved class names to: {class_names_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRAINING PIPELINE COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nCheckpoints directory: {CHECKPOINT_DIR}\")\n",
    "print(f\"Final models directory: {FINAL_MODELS_DIR}\")\n",
    "print(f\"Visualization files: training_curves.png, individual_training_curves.png, model_comparison.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
